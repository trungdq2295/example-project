S3 - Baseline performance
    Automatically scale to high request rates, latency from 100-200ms
    Your application can achieve at least 3,500 PUT/COPY/DELETE or 5,500 GET/HEAD RPS per prefix in a bucket
    There are no limits to the number of prefixes in a bucket

S3 - Performance
    Multi-Part upload:
        recommended for files > 100 MB, must use for file >5 GB
        Can help parallelize uploads ( speed up transfer)
    S3 Transfer Acceleration
        Increase transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region
        Compatible with multi-part upload
        Flow:
            File(from USA) upload to Edge Location (USA) through public IP
            Edge location will upload to S3 through private IP
            => to maximize the private AWS network we go through
    S3 Byte-Range fetches
        Parallelize GETs by requesting specific byte ranges
        Better resilience in case of failures
        The idea is to split a file into ranges of bytes
            and we process all the ranges parallel
            and if it's fail in a range, we only retry that range => smaller bytes to retry
        Can be used to retrieve only partial data

